Гибридная система рекомендаций книг с нейросетевыми моделями

Этот проект — итоговое задание по курсу «Рекомендательные системы / MLOps».
Цель работы: построить гибридную систему рекомендаций книг, которая объединяет классические подходы (популярность, контентные признаки, коллаборативная фильтрация, матричная факторизация) и простой нейросетевой two-tower подход, а также оформить всё это в виде сквозного пайплайна «от данных до метрик».

Основной артефакт проекта — Jupyter Notebook с подробными комментариями и визуализацией результатов.

1. Данные

В проекте используются стандартные данные по книгам и оценкам (goodbooks-10k или аналогичный датасет):

books — справочник книг (book_id, title, authors, дополнительные поля).

ratings — пользовательские оценки (user_id, book_id, rating).

tags, book_tags — теги и связи книг с тегами.

На основе исходных данных выполняется:

разбиение ratings на train_df и test_df по пользователям;

фильтрация пользователей с малым числом оценок для корректной оценки метрик;

объединение таблиц книг и тегов.

2. Расширенные признаки (feature engineering)

Для улучшения качества рекомендаций были построены расширенные признаки:

Признаки пользователей

user_mean_rating — средний рейтинг пользователя по его оценкам в train;

user_num_ratings — количество оценок;

user_activity — логарифм количества оценок (приближённая мера активности).

Признаки книг

book_num_ratings — количество оценок книги;

book_mean_rating — средний рейтинг книги;

book_rating_std — стандартное отклонение рейтингов;

tags_str — конкатенация тегов книги;

content_str — простое текстовое описание книги (название + теги).

Признаки взаимодействий

sim_with_history — косинусная похожесть книги с «профилем» пользователя, построенным по TF-IDF-вектору его любимых книг (рейтинг ≥ 4).

Результаты объединены в расширенные таблицы train_ext и test_ext, которые затем используются и в классических моделях, и в нейросетевой части.

3. Классические модели рекомендаций

В ноутбуке реализованы и сравниваются следующие модели:

Модель популярности
Рекомендует топ-N самых популярных книг (по book_num_ratings).

Контентная модель (content-based)

Строится TF-IDF по content_str (название + теги).

Для пользователя усредняются TF-IDF вектора его любимых книг → профиль пользователя.

Книги ранжируются по косинусной похожести с этим профилем.

Item-based коллаборативная фильтрация

Строится разреженная матрица user × book в формате CSR (без pivot!).

Для каждого пользователя по его оценённым книгам считаются косинусные похожести всех книг к этим оценённым (через item_user_matrix).

Итоговый скор для книги = сумма(similarity × rating) по всем оценённым книгам пользователя.

Матричная факторизация (SVD)

Реализована простая SVD-модель для предсказания рейтингов.

Обучается несколько эпох, loss и RMSE постепенно снижаются.

Все модели реализованы в виде функций recommend_*, возвращающих DataFrame с рекомендациями.

4. Гибридная система (классический гибрид)

На основе классических моделей построен гибрид:

Генерация кандидатов — объединение множества топ-N списков от разных моделей (popular, content, item_cf, svd).

Скоринг кандидатов — для каждой книги считаются:

score_pop (нормированный ранг по популярности),

score_svd (предсказанный SVD рейтинг),

score_cont (похожесть по контенту с историей),

score_cf (item-based CF скор).

Комбинация скорингов — линейная комбинация указанных сигналов с фиксированными весами.

Диверсификация — дополнительное переупорядочивание с учётом различия тегов, чтобы не получать слишком однородный список.

Итоговая функция:
recommend_hybrid_classic(user_id, n=10) — возвращает top-N книг для заданного пользователя.

5. Нейросетевая модель (two-tower) и полный гибрид

В продвинутой части реализована простая two-tower нейросетевая модель:

Входы:

индексы пользователя и книги (эмбеддинги),

часть числовых признаков (например, sim_with_history, статистика книг и пользователей).

Архитектура:

две «башни» (user-tower и item-tower) с линейными слоями и нелинейностями;

финальный скор — скалярное произведение эмбеддингов + учёт дополнительных фич.

Лосс:

MSE между предсказанным скором и нормированным рейтингом.

По итогам обучения нейросеть:

используется как отдельный ранжировщик (nn_only);

интегрируется в гибридную модель (hybrid_full) как дополнительный скоринг-сигнал.

6. Метрики и сравнение моделей

Для оценки качества используются стандартные метрики:

Precision@K, Recall@K, nDCG@K (обычно при K = 10),

метрики считаются по тестовой выборке для пользователей, у которых в тесте ≥ 3 оценок,

для ускорения рассчитываются на случайной подвыборке пользователей.

Результаты:

Считаются сводные таблицы metrics_summary (классические модели) и metrics_nn_summary (включая NN).

Строятся bar-графики для наглядного сравнения моделей.

По метрикам лучше всего себя показала item-based CF, гибрид лучше простых моделей, а нейросетевая часть в текущей конфигурации не даёт выигрыша над классическими методами.

7. Анализ и выводы

В ноутбуке в виде markdown-блоков подробно разобрано:

Анализ эффективности гибридного подхода — сравнение гибрида с базовыми моделями.

Анализ нейросетевого подхода — обсуждение результатов two-tower модели и причин низких метрик.

Сильные и слабые стороны методов — по каждому подходу отдельно.

Итоговые выводы и рекомендации — какая модель лучше подходит в качестве «ядра» системы, как использовать гибрид и как можно дальше улучшать нейросетевую часть.

Кратко: item-based CF остаётся самым практичным и эффективным базовым решением, а нейросетевая модель и гибриды демонстрируют потенциал при дальнейшем тюнинге.

8. Сквозной пайплайн и MLOps-аспекты

В конце ноутбука описан и частично реализован сквозной пайплайн:

Загрузка и разбиение данных.

Построение расширенных признаков пользователей, книг и взаимодействий.

Обучение классических моделей (популярность, контент, item-CF, SVD).

Обучение нейросетевой two-tower модели.

Оффлайн-оценка качества и сравнение моделей.

Генерация рекомендаций для выбранного пользователя.

Показан эскиз функции run_full_pipeline(...), которая иллюстрирует структуру процесса. В текстовом описании (markdown) обсуждается, как этот ноутбук можно перенести в полноценный MLOps-контур (например, через Airflow/Kubeflow) с автоматическим переобучением и мониторингом метрик.

9. Как запустить

Установить зависимости (пример для окружения с pip):

pip install numpy pandas scipy scikit-learn matplotlib tqdm torch


Открыть Jupyter Notebook (либо через jupyter lab, либо в Google Colab).

Загрузить данные (пути к файлам указаны в начале ноутбука) и последовательно выполнить все ячейки сверху вниз:

загрузка данных и построение признаков,

обучение классических моделей,

обучение нейросети,

расчёт метрик и визуализация,

блоки с анализом и выводами.

При желании можно изменить некоторые параметры в ноутбуке, например:

k_eval — размер топ-N списка для метрик,

количество пользователей для оценки (семплирование),

число эпох и размер эмбеддингов для SVD и нейросети.

10. Структура проекта

В минимальном варианте:

Recommender_System_Final.ipynb — основной ноутбук с кодом, визуализацией и анализом.

README.md — данный файл с описанием логики решения и структуры проекта.

(опционально) папка data/ с исходными CSV-файлами датасета.
